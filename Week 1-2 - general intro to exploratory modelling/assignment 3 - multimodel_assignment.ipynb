{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPA1361 - Model-Based Decision Making\n",
    "\n",
    "## Multi-model analysis\n",
    "\n",
    "This exercise uses a simple version of the [Lotka-Volterra predator-prey equations](https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations) to show how the EMA Workbench can be used for a\n",
    "multi-model analysis, in addition to typical parametric/structural uncertainties. This will let you test the connectors provided in the Workbench for Excel, NetLogo, and Vensim / PySD; we'll also use the models for the sensitivity analysis exercise in week 3.\n",
    "\n",
    "**Assignment**\n",
    "Using the three model files provided and the Python function below, define model objects for each implementation (Excel, NetLogo, Vensim/PySD, and Python), and test them using a single ensemble. Use 50 experiments sampled from the parameters below (so that each experiment will be executed for the 4 models, for a total of 200), and retrieve outputs for the _TIME_, _predators_, and _prey_ variables.\n",
    "   * Excel and Vensim are only supported on Windows\n",
    "   * Vensim requires the DSS version of Vensim\n",
    "   * Netlogo supoprt depends on [jpype](http://jpype.readthedocs.io/en/latest/install.html) and [pynetlogo](https://pynetlogo.readthedocs.io/en/latest/). Also, if you don't have NetLogo installed, please get [NetLogo 6.3.0](https://ccl.northwestern.edu/netlogo/download.shtml)\n",
    "   * for pysd, see [its documentation](http://pysd.readthedocs.io/en/master/installation.html)\n",
    "   * If possible try to work with all model versions, but even 2 or 3 (pure python and something else should be sufficient).\n",
    "\n",
    "\n",
    "|Parameter\t|Range or value\t        |\n",
    "|-----------|--------------:|\n",
    "|prey_birth_rate    \t|0.015 – 0.035\t|\n",
    "|predation_rate|0.0005 – 0.003 \t|\n",
    "|predator_efficiency     \t|0.001 – 0.004\t    |\n",
    "|predator_loss_rate\t    |0.04 – 0.08\t    |\n",
    "|Final time\t    |365\t    |\n",
    "|dt\t    |0.25\t    |\n",
    "\n",
    "* Note that your EMA Workbench installation includes [example scripts](https://github.com/quaquel/EMAworkbench/tree/master/ema_workbench/examples) for the different connectors. The different model objects follow a similar syntax but will need to be slightly adjusted depending on the software (e.g. to specify the NetLogo run length or the sheet name in Excel).\n",
    "  * This [tutorial](https://emaworkbench.readthedocs.io/en/latest/basic_tutorial.html) also shows a simple model in Python, Vensim and Excel connected to the workbench.\n",
    "\n",
    "* These model objects can be used with a replication functionality (for instance to test the effect of stochastic uncertainty in a NetLogo model), which repeats a given experiment over multiple replications. You can use a single replication in this exercise as the models are not stochastic. By default, each outcome array will then have a shape of (# experiments, # replications, # time steps). Try adapting the outcome arrays so that they can be used with the _lines_ plotting function of the Workbench, and plot the results grouped by model.\n",
    "\n",
    "* To check the graphical results, find the maximum absolute error of the time series you obtained for the _prey_ variable in the Excel, NetLogo, and Vensim/PySD models, relative to the Python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T13:56:51.448651Z",
     "start_time": "2023-04-07T13:56:49.471035Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juliu\\anaconda3\\envs\\gds24\\lib\\site-packages\\ema_workbench\\connectors\\__init__.py:19: ImportWarning: vensim connector not available\n",
      "  warnings.warn(\"vensim connector not available\", ImportWarning)\n",
      "c:\\Users\\juliu\\anaconda3\\envs\\gds24\\lib\\site-packages\\ema_workbench\\connectors\\__init__.py:34: ImportWarning: simio connector not available\n",
      "  warnings.warn(\"simio connector not available\", ImportWarning)\n"
     ]
    }
   ],
   "source": [
    "# Some imports you may need\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ema_workbench import (Model, RealParameter, TimeSeriesOutcome, perform_experiments, ema_logging)\n",
    "\n",
    "from ema_workbench.connectors.netlogo import NetLogoModel\n",
    "from ema_workbench.connectors.excel import ExcelModel\n",
    "from ema_workbench.connectors.pysd_connector import PysdModel\n",
    "\n",
    "from ema_workbench.em_framework.samplers import LHSSampler\n",
    "from ema_workbench.em_framework.salib_samplers import MorrisSampler, SobolSampler\n",
    "\n",
    "from ema_workbench.analysis.plotting import lines, Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Instantia\n",
    "sys.path.append(os.path.abspath('model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T13:56:51.450975Z",
     "start_time": "2023-04-07T13:56:51.445849Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model.pred_prey'; 'model' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import the Python function\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpred_prey\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PredPrey\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Add the path to the 'model' directory manually\u001b[39;00m\n\u001b[0;32m      5\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'model.pred_prey'; 'model' is not a package"
     ]
    }
   ],
   "source": [
    "# Import the Python function\n",
    "from model.pred_prey import PredPrey\n",
    "\n",
    "# Add the path to the 'model' directory manually\n",
    "sys.path.append(os.path.abspath('model'))\n",
    "def getmod(function, mod_ki='py'):\n",
    "    if mod_ki == 'py':\n",
    "        model = Model('pred', function=function)\n",
    "    return model\n",
    "model = getmod(PredPrey)\n",
    "#model.time_horizon = 365/0.25\n",
    "# Specify uncertainties\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T13:56:51.453653Z",
     "start_time": "2023-04-07T13:56:51.450975Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from ema_workbench import (\n",
    "    Model,\n",
    "    RealParameter,\n",
    "    ScalarOutcome,\n",
    "    ema_logging,\n",
    "    MultiprocessingEvaluator,\n",
    "    Constraint,\n",
    ")\n",
    "\n",
    "# Define uncertainties and outcomes\n",
    "model.uncertainties = [RealParameter('prey_birh_rate', 0.015, 0.035),\n",
    "                       RealParameter('predation_rate', 0.0005, 0.003),\n",
    "                       RealParameter('predator_efficiency', 0.001, 0.004),\n",
    "                       RealParameter('predator_loss_rate', 0.04, 0.08),\n",
    "                       ]\n",
    "\n",
    "\n",
    "# Define model objects for the different implementations\n",
    "\n",
    "\n",
    "\n",
    "model.outcomes = [\n",
    "        ScalarOutcome('TIME', kind=ScalarOutcome.MINIMIZE, expected_range=(0, 5)),\n",
    "        ScalarOutcome('predators', kind=ScalarOutcome.MAXIMIZE, expected_range=(0, 2)),\n",
    "        ScalarOutcome('prey', kind=ScalarOutcome.MAXIMIZE, expected_range=(0, 1)),]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/50 [00:00<?, ?it/s]PredPrey() got an unexpected keyword argument 'prey_birh_rate'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\juliu\\anaconda3\\envs\\gds24\\lib\\site-packages\\ema_workbench\\em_framework\\experiment_runner.py\", line 92, in run_experiment\n",
      "    model.run_model(scenario, policy)\n",
      "  File \"c:\\Users\\juliu\\anaconda3\\envs\\gds24\\lib\\site-packages\\ema_workbench\\util\\ema_logging.py\", line 153, in wrapper\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\juliu\\anaconda3\\envs\\gds24\\lib\\site-packages\\ema_workbench\\em_framework\\model.py\", line 347, in run_model\n",
      "    outputs = self.run_experiment(experiment)\n",
      "  File \"c:\\Users\\juliu\\anaconda3\\envs\\gds24\\lib\\site-packages\\ema_workbench\\util\\ema_logging.py\", line 153, in wrapper\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\juliu\\anaconda3\\envs\\gds24\\lib\\site-packages\\ema_workbench\\em_framework\\model.py\", line 400, in run_experiment\n",
      "    model_output = self.function(**experiment)\n",
      "TypeError: PredPrey() got an unexpected keyword argument 'prey_birh_rate'\n"
     ]
    },
    {
     "ename": "EMAError",
     "evalue": "Exception in run_model\nCaused by: TypeError: PredPrey() got an unexpected keyword argument 'prey_birh_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\juliu\\anaconda3\\envs\\gds24\\lib\\site-packages\\ema_workbench\\em_framework\\experiment_runner.py:92\u001b[0m, in \u001b[0;36mExperimentRunner.run_experiment\u001b[1;34m(self, experiment)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscenario\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CaseError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\juliu\\anaconda3\\envs\\gds24\\lib\\site-packages\\ema_workbench\\util\\ema_logging.py:153\u001b[0m, in \u001b[0;36mmethod_logger.<locals>.real_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclassname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 153\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    154\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleted calling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclassname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\juliu\\anaconda3\\envs\\gds24\\lib\\site-packages\\ema_workbench\\em_framework\\model.py:347\u001b[0m, in \u001b[0;36mSingleReplication.run_model\u001b[1;34m(self, scenario, policy)\u001b[0m\n\u001b[0;32m    345\u001b[0m experiment \u001b[38;5;241m=\u001b[39m ExperimentReplication(scenario, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy, constants)\n\u001b[1;32m--> 347\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutcomes_output \u001b[38;5;241m=\u001b[39m outputs\n",
      "File \u001b[1;32mc:\\Users\\juliu\\anaconda3\\envs\\gds24\\lib\\site-packages\\ema_workbench\\util\\ema_logging.py:153\u001b[0m, in \u001b[0;36mmethod_logger.<locals>.real_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclassname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 153\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    154\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleted calling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclassname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\juliu\\anaconda3\\envs\\gds24\\lib\\site-packages\\ema_workbench\\em_framework\\model.py:400\u001b[0m, in \u001b[0;36mBaseModel.run_experiment\u001b[1;34m(self, experiment)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Method for running an instantiated model structure.\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \n\u001b[0;32m    395\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    398\u001b[0m \n\u001b[0;32m    399\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 400\u001b[0m model_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexperiment)\n\u001b[0;32m    402\u001b[0m \u001b[38;5;66;03m# TODO: might it be possible to somehow abstract this\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;66;03m# perhaps expose a get_data on modelInterface?\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;66;03m# different connectors can than implement only this\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;66;03m# get method\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: PredPrey() got an unexpected keyword argument 'prey_birh_rate'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mEMAError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# with MultiprocessingEvaluator(model) as evaluator:\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#     experimenents, outcomes = evaluator.perform_experiments(n_scenarios, n_policies, lever_sampling=Samplers.MC)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SequentialEvaluator(model) \u001b[38;5;28;01mas\u001b[39;00m evaluator:\n\u001b[1;32m----> 8\u001b[0m     experiments, outcomes \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_experiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscenarios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\juliu\\anaconda3\\envs\\gds24\\lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py:193\u001b[0m, in \u001b[0;36mBaseEvaluator.perform_experiments\u001b[1;34m(self, scenarios, policies, reporting_interval, reporting_frequency, uncertainty_union, lever_union, outcome_union, uncertainty_sampling, lever_sampling, callback, combine, **kwargs)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperform_experiments\u001b[39m(\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    174\u001b[0m     scenarios\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    186\u001b[0m ):\n\u001b[0;32m    187\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"convenience method for performing experiments.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03m    is forwarded to :func:perform_experiments, with evaluator and\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m    models arguments added in.\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \n\u001b[0;32m    192\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m perform_experiments(\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_msis,\n\u001b[0;32m    195\u001b[0m         scenarios\u001b[38;5;241m=\u001b[39mscenarios,\n\u001b[0;32m    196\u001b[0m         policies\u001b[38;5;241m=\u001b[39mpolicies,\n\u001b[0;32m    197\u001b[0m         evaluator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    198\u001b[0m         reporting_interval\u001b[38;5;241m=\u001b[39mreporting_interval,\n\u001b[0;32m    199\u001b[0m         reporting_frequency\u001b[38;5;241m=\u001b[39mreporting_frequency,\n\u001b[0;32m    200\u001b[0m         uncertainty_union\u001b[38;5;241m=\u001b[39muncertainty_union,\n\u001b[0;32m    201\u001b[0m         lever_union\u001b[38;5;241m=\u001b[39mlever_union,\n\u001b[0;32m    202\u001b[0m         outcome_union\u001b[38;5;241m=\u001b[39moutcome_union,\n\u001b[0;32m    203\u001b[0m         uncertainty_sampling\u001b[38;5;241m=\u001b[39muncertainty_sampling,\n\u001b[0;32m    204\u001b[0m         lever_sampling\u001b[38;5;241m=\u001b[39mlever_sampling,\n\u001b[0;32m    205\u001b[0m         callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    206\u001b[0m         combine\u001b[38;5;241m=\u001b[39mcombine,\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    208\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\juliu\\anaconda3\\envs\\gds24\\lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py:406\u001b[0m, in \u001b[0;36mperform_experiments\u001b[1;34m(models, scenarios, policies, evaluator, reporting_interval, reporting_frequency, uncertainty_union, lever_union, outcome_union, uncertainty_sampling, lever_sampling, callback, return_callback, combine, log_progress, **kwargs)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evaluator:\n\u001b[0;32m    404\u001b[0m     evaluator \u001b[38;5;241m=\u001b[39m SequentialEvaluator(models)\n\u001b[1;32m--> 406\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mevaluate_experiments(scenarios, policies, callback, combine\u001b[38;5;241m=\u001b[39mcombine, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callback\u001b[38;5;241m.\u001b[39mi \u001b[38;5;241m!=\u001b[39m nr_of_exp:\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EMAError(\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome fatal error has occurred while running the experiments, not all runs have completed. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnr_of_exp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcallback\u001b[38;5;241m.\u001b[39mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\juliu\\anaconda3\\envs\\gds24\\lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py:291\u001b[0m, in \u001b[0;36mSequentialEvaluator.evaluate_experiments\u001b[1;34m(self, scenarios, policies, callback, combine)\u001b[0m\n\u001b[0;32m    288\u001b[0m runner \u001b[38;5;241m=\u001b[39m ExperimentRunner(models)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m experiment \u001b[38;5;129;01min\u001b[39;00m ex_gen:\n\u001b[1;32m--> 291\u001b[0m     outcomes \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m     callback(experiment, outcomes)\n\u001b[0;32m    293\u001b[0m runner\u001b[38;5;241m.\u001b[39mcleanup()\n",
      "File \u001b[1;32mc:\\Users\\juliu\\anaconda3\\envs\\gds24\\lib\\site-packages\\ema_workbench\\util\\ema_logging.py:153\u001b[0m, in \u001b[0;36mmethod_logger.<locals>.real_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;66;03m# hack, because log is applied to methods, we can get\u001b[39;00m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;66;03m# object instance as first arguments in args\u001b[39;00m\n\u001b[0;32m    152\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclassname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 153\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    154\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleted calling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclassname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\juliu\\anaconda3\\envs\\gds24\\lib\\site-packages\\ema_workbench\\em_framework\\experiment_runner.py:108\u001b[0m, in \u001b[0;36mExperimentRunner.run_experiment\u001b[1;34m(self, experiment)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;66;03m#             exception = traceback.print_exc()\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;66;03m#             if exception:\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;66;03m#                 sys.stderr.write(exception)\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;66;03m#                 sys.stderr.write(\"\\n\")\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     errortype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(e)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EMAError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException in run_model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCaused by: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merrortype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    110\u001b[0m outcomes \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39moutcomes_output\n\u001b[0;32m    111\u001b[0m model\u001b[38;5;241m.\u001b[39mreset_model()\n",
      "\u001b[1;31mEMAError\u001b[0m: Exception in run_model\nCaused by: TypeError: PredPrey() got an unexpected keyword argument 'prey_birh_rate'"
     ]
    }
   ],
   "source": [
    "from ema_workbench import SequentialEvaluator\n",
    "from ema_workbench.em_framework.optimization import HyperVolume, EpsilonProgress\n",
    "from ema_workbench.em_framework.evaluators import Samplers\n",
    "\n",
    "# with MultiprocessingEvaluator(model) as evaluator:\n",
    "#     experimenents, outcomes = evaluator.perform_experiments(n_scenarios, n_policies, lever_sampling=Samplers.MC)\n",
    "with SequentialEvaluator(model) as evaluator:\n",
    "    experiments, outcomes = evaluator.perform_experiments(scenarios=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Plot prey and predator over time for the first experiment\n",
    "prey = outcomes['prey'][0]\n",
    "predators = outcomes['predators'][0]\n",
    "time = outcomes['TIME'][0]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(time, prey, label='Prey')\n",
    "plt.plot(time, predators, label='Predators')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Population')\n",
    "plt.title('Predator-Prey Dynamics Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gds24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
